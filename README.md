# ğŸ“± Mobile Price Classification Analysis

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Complete-success.svg)]()

## ğŸš€ Project Overview

This project implements and compares **6 different machine learning classification algorithms** to predict mobile phone price ranges. The analysis provides comprehensive performance evaluation with detailed visualizations to determine the most effective approach for multi-class classification.

> **ğŸ¯ Key Achievement:** 96.5% Peak Accuracy achieved with Logistic Regression

## ğŸ“ Academic Information

**ğŸ“š Course:** Machine Learning (Semester 3-2)  
**ğŸ›ï¸ Institution:** ACE Engineering College  
**ğŸ‘©â€ğŸ« Faculty Guide:** Mrs. Swaroopa Mam, Assistant Professor  
**ğŸ‘¨â€ğŸ’» Student:** [Mohan Krishna Thalla] - GitHub: [mohan13krishna](https://github.com/mohan13krishna)

## ğŸ”§ Technologies Used

- **Python 3.x**
- **Libraries:** pandas, numpy, matplotlib, seaborn, scikit-learn

## ğŸ¤– Algorithms Implemented

| Algorithm | Output File | Key Strength |
|-----------|-------------|--------------|
| ğŸ”µ **Logistic Regression** | `Output-2.png` | Probability estimates & interpretability |
| ğŸŒ³ **Decision Tree** | `Output-3.png` | Rule interpretability & feature importance |
| ğŸŒ² **Random Forest** | `Output-4.png` | Reduces overfitting & robust performance |
| âš¡ **Support Vector Machine** | `Output-5.png` | Effective in high dimensions |
| ğŸ‘¥ **K-Nearest Neighbors** | `Output-6.png` | Non-parametric & local patterns |
| ğŸ¯ **Naive Bayes** | `Output-7.png` | Fast training & probabilistic approach |

## ğŸ“Š Dataset Information

- **Training Samples:** 2000 | **Test Samples:** 1000
- **Features:** 20 mobile specifications (battery, RAM, camera, connectivity, etc.)
- **Target:** `price_range` (0: Low Cost, 1: Medium, 2: High, 3: Very High)
- **Preprocessing:** Feature scaling and stratified validation splitting

## ğŸš€ Quick Start

1. **Clone the repository:**
   ```bash
   git clone https://github.com/mohan13krishna/Mobile-price-classification-analysis.git
   cd Mobile-price-classification-analysis
   ```

2. **Install dependencies:**
   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn
   ```

3. **Run the analysis:**
   ```bash
   python classification_analysis.py
   ```

## ğŸ† Performance Results

| Rank | Algorithm | Accuracy | Performance Grade |
|------|-----------|----------|------------------|
| **1st** ğŸ† | **Logistic Regression** | **96.5%** | **A+** â­â­â­â­â­ |
| **2nd** ğŸ¥ˆ | **SVM** | **89.5%** | **A-** â­â­â­â­ |
| **3rd** ğŸ¥‰ | **Random Forest** | **88.0%** | **B+** â­â­â­â­ |
| 4th | Decision Tree | 83.0% | B â­â­â­ |
| 5th | Naive Bayes | 81.0% | B- â­â­â­ |
| 6th | KNN | 50.0% | F â­ |

### Key Insights:
- **Logistic Regression** dominates with 96.5% accuracy across all price categories
- **Linear methods** significantly outperform instance-based approaches
- **Feature scaling** proves critical for optimal performance

## ğŸ“‹ Generated Outputs

| Output File | Content | Purpose |
|-------------|---------|---------|
| `Output-1.png` | Test Table | Initial data validation |
| `Output-2.png` | Logistic Regression CM | Linear classification analysis |
| `Output-3.png` | Decision Tree CM | Tree-based prediction |
| `Output-4.png` | Random Forest CM | Ensemble method performance |
| `Output-5.png` | SVM CM | Support vector classification |
| `Output-6.png` | KNN CM | Nearest neighbor analysis |
| `Output-7.png` | Naive Bayes CM | Probabilistic classification |
| `Output-8.png` | Performance Summary | Comparative analysis table |

## ğŸ“ Project Structure

```
Mobile-price-classification-analysis/
â”œâ”€â”€ ğŸ“„ classification_analysis.py    # Main analysis script
â”œâ”€â”€ ğŸ“Š train.csv                    # Training dataset
â”œâ”€â”€ ğŸ“Š test.csv                     # Testing dataset  
â”œâ”€â”€ ğŸ“– README.md                    # Documentation
â””â”€â”€ ğŸ“ Results/                     # Generated visualizations
    â”œâ”€â”€ Output-1.png               # Test Table
    â”œâ”€â”€ Output-2.png               # Logistic Regression CM
    â”œâ”€â”€ Output-3.png               # Decision Tree CM
    â”œâ”€â”€ Output-4.png               # Random Forest CM
    â”œâ”€â”€ Output-5.png               # SVM CM
    â”œâ”€â”€ Output-6.png               # KNN CM
    â”œâ”€â”€ Output-7.png               # Naive Bayes CM
    â””â”€â”€ Output-8.png               # Performance Summary
```

## ğŸ¤ Contributing

Contributions welcome! Ideas for improvement:
- Add more algorithms (XGBoost, LightGBM)
- Implement hyperparameter tuning
- Create interactive visualizations
- Add cross-validation analysis

## â­ Show Your Support

If this project helped you:
- â­ **Star** the repository
- ğŸ´ **Fork** for your experiments  
- ğŸ“¢ **Share** with ML enthusiasts

---

## ğŸ“ Contact

**ğŸ‘¨â€ğŸ’» Developer:** [Mohan Krishna Thalla]  
**ğŸ”— GitHub:** [mohan13krishna](https://github.com/mohan13krishna)  


---

<div align="center">

### ğŸŒŸ "Transforming Data into Insights, One Algorithm at a Time" ğŸŒŸ

**Made with â¤ï¸ for Machine Learning Education**

</div>
